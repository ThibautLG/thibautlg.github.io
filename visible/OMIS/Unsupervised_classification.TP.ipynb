{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification non supervisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TP noté, à déposer sur Claroline (OMI_5AP_SMCG) en fin de séance **\n",
    "\n",
    "Ce TP s'intéresse à deux méthodes de classification non supervisée: les $k$-means et les modèles de mélanges gaussiens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import Isomap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $k$-means\n",
    "\n",
    "#### Génération des données\n",
    "\n",
    "Pour commmencer, on génère des variables aléatoires sur $\\mathbb{R}^2$ selon la loi:\n",
    "$$ p \\mathcal{N}(c_1,Id) + (1-p)\\mathcal{N}(c_2,Id),$$\n",
    "où $c_1$ et $c_2$ sont deux points de $\\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_samples=750\n",
    "p=0.65\n",
    "centers=np.array([[ -1.60834549, 1.3667341], [1.40887718, -1.5253229]])\n",
    "\n",
    "\n",
    "X=np.random.normal(size=2*n_samples).reshape(2,n_samples)\n",
    "\n",
    "\n",
    "delta=np.random.binomial(1,p,size=n_samples).reshape(1,-1)\n",
    "X=(np.dot(centers[0].reshape(-1,1),delta)+ np.dot(centers[1].reshape(-1,1),1-delta))+X\n",
    "X=X.transpose()\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1],c=delta,cmap=\"spring\")\n",
    "plt.title(\"Melange de gaussiennes\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résultats\n",
    "\n",
    "On applique la méthode `KMeans` classer les points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = KMeans(n_clusters=2).fit_predict(X)\n",
    "\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1],c=y_pred,cmap=\"spring\")\n",
    "plt.title(\"Melange de gaussiennes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cas insatisfaisants\n",
    "\n",
    "#### Mauvais nombre de clusters\n",
    "Si le nombre $k$ de clusters est mal choisi, on obtient alors une résultat qui ne correspond pas à ce que l'on souhaite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = KMeans(n_clusters=3).fit_predict(X)\n",
    "\n",
    "xmin=min(X.ravel())\n",
    "xmax=max(X.ravel())\n",
    "plt.xlim(xmin,xmax)  # set the xlim to xmin, xmax\n",
    "plt.ylim(xmin,xmax)\n",
    "plt.scatter(X[:,0],X[:,1],c=y_pred,cmap=\"spring\")\n",
    "plt.title(\"Melange de gaussiennes: mauvais nombre de clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anisotropie\n",
    "Autre cas où les $k$-means se révèlent peu efficaces: si les gaussiennes qui génèrent les variables aléatoires sont anisotropes, les centroides ne séparent pas *correctement* les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigma=[[2,4],[4,18]]\n",
    "p=0.65\n",
    "centers=np.array([[ -1.60834549, 4.63667341], [1.40887718, -2.85253229]])\n",
    "\n",
    "\n",
    "X=np.random.normal(size=2*n_samples).reshape(2,n_samples)\n",
    "L=np.linalg.cholesky(sigma)\n",
    "X=np.dot(L,X)\n",
    "\n",
    "delta=np.random.binomial(1,p,size=n_samples).reshape(1,-1)\n",
    "X=(np.dot(centers[0].reshape(-1,1),delta)+ np.dot(centers[1].reshape(-1,1),1-delta))+X\n",
    "X=X.transpose()\n",
    "\n",
    "y_pred = KMeans(n_clusters=2).fit_predict(X)\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1],c=y_pred,cmap=\"spring\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support non linéaire\n",
    "\n",
    "Voici encore un cas pour lequel les $k$-means seuls ne fonctionnent pas.\n",
    "Si le support de la mesure de probabilité qui génère les variables aléatoires n'est pas convexe, cela peut aussi poser problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples = 1500\n",
    "np.random.seed(0)\n",
    "p = 0.7\n",
    "Zc= np.random.rand(1, n_samples)<p\n",
    "Z = (np.random.rand(1, n_samples)-1+Zc)\n",
    "t = np.pi * Z\n",
    "x = np.sin(t)\n",
    "y = (t-3*np.pi/4)*t*(t+3*np.pi/4)\n",
    "\n",
    "X = np.concatenate((x, y))\n",
    "X = X.T\n",
    "plt.figure(figsize=(40, 20))\n",
    "plt.subplot(243)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Zc, cmap=\"spring\");\n",
    "\n",
    "y_pred = KMeans(n_clusters=2).fit_predict(X)\n",
    "plt.subplot(242)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap=\"spring\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ISOMAP\n",
    "\n",
    "Pour parer à ce dernier problème, on peut utiliser un algorithme de réduction de dimension.\n",
    "Isomap est un algorithme qui permet de définir une nouvelle distance sur les données, qui rend compte de la structure des données.\n",
    "La classe `Isomap` de `scikitlearn.manifold` implémente cette algorithme.\n",
    "Une matrice contenant les distances est renvoyée.\n",
    "\n",
    "Elle est ici contenue dans `distmat`.\n",
    "*La distance entre `X[i]` et `X[j]` est dans `distmat[i][j]` ou `distmat[j][i]`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "man=Isomap(n_neighbors=int(np.ceil(np.log(n_samples)))).fit(X)\n",
    "distmat=man.dist_matrix_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ISOMAP et $k$-means\n",
    "\n",
    "La distance étant définie uniquement sur les points observés, on définit le minimum sur les centroides sur les points observés.\n",
    "\n",
    "On va utiliser la matrice `distmat` que l'on a généré avec ISOMAP pour construire les $k$-means.\n",
    "Pour ça, on va implémenter pas à pas l'algorithme de LLoyd.\n",
    "\n",
    "*Exercice :*\n",
    "**Définir une fonction `distorsion` qui prend deux arguments: une liste d'indices `list` et un indice `i`; et renvoie **\n",
    "$$ \\sum_{j\\in list} d(X[j],X[i])^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distorsion(X,index):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**À l'aide de la fonction `distorsion`, définir une fonction `centroides` qui prend deux arguments: les données `X` et une liste de deux indices `c_index` et renvoie les centroides (i.e. barycentres) de chaque cellule de Voronoï définie par les centres`X[c_index[0]]`.et `X[c_index[1]]`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def better_centroid(X,c_index):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Définir une fonction `lloyd` qui prend en arguments les données `X`, et deux paramètres `init` et `epsilon` et execute l'algorithme de Lloyd avec un nombre `init` d'initilisations aléatoires et s'arrête à chaque fois si les nouveaux centroides n'améliorent pas la distorsion de plus de `epsilon`.\n",
    "La fonction renvoie alors le centroides et la distorsion.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lloyd(X,init,epsilon):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tester votre code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dis,c=lloyd(X,10,10**-6)\n",
    "print dis,c\n",
    "predict=np.array([np.argmin([distmat[i][c[0]],distmat[i][c[1]]]) for i in range(n_samples)])\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1],c=predict, cmap=\"spring\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèles de mélange gaussien\n",
    "\n",
    "La deuxième méthode que l'on va étudier est celle de l'estimateur du maximum de vraisemblance des mélanges gaussiens.\n",
    "\n",
    "### Cas homoscédastique\n",
    "\n",
    "#### Génération des données\n",
    "Dans un premier temps, on s'intéresse au cas où les données sont généré par un mélange de deux gaussiennes ayant la même matrice de covariance.\n",
    "\n",
    "On commence par générer ces données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples=750\n",
    "\n",
    "sigma=[[2,4],[4,18]]\n",
    "p=0.65\n",
    "centers=np.array([[ -1.60834549, 4.63667341], [1.40887718, -2.85253229]])\n",
    "\n",
    "\n",
    "X=np.random.normal(size=2*n_samples).reshape(2,n_samples)\n",
    "L=np.linalg.cholesky(sigma)\n",
    "X=np.dot(L,X)\n",
    "\n",
    "delta=np.random.binomial(1,p,size=n_samples).reshape(1,-1)\n",
    "X=(np.dot(centers[0].reshape(-1,1),delta)+ np.dot(centers[1].reshape(-1,1),1-delta))+X\n",
    "X=X.transpose()\n",
    "\n",
    "xmin=min(X.ravel())\n",
    "xmax=max(X.ravel())\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(xmin,xmax)\n",
    "plt.scatter(X[:,0],X[:,1],c=delta,cmap=\"spring\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résultats\n",
    "\n",
    "*Exercice: *\n",
    "**Utiliser la méthode GMM dans le cas hétéroscédastique, sans contrainte sur la matrice de covariance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(GMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cas hétéroscédastique - cas unidimensionnel\n",
    "#### Génération des données\n",
    "*Exercice: *\n",
    "**Modifier le code précédent pour simuler des données suivant la loi \n",
    "$$ p\\mathcal{N}(m_1,\\sigma_1) + (1-p)\\mathcal{N}(m_2,\\sigma_2) $$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples=750\n",
    "\n",
    "sigma1=[[2,4],[4,18]]\n",
    "sigma2=[[10,4],[4,2]]\n",
    "p=0.65\n",
    "centers=np.array([[ -1.60834549, 4.63667341], [1.40887718, -2.85253229]])\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "xmin=min(X.ravel())\n",
    "xmax=max(X.ravel())\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(xmin,xmax)\n",
    "plt.scatter(X[:,0],X[:,1],c=delta,cmap=\"spring\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résultats\n",
    "\n",
    "*Exercice:*\n",
    "**Implémenter l'algorithme EM pour la dimension 1, avec deux composantes et sur la contrainte $\\sigma_1/\\sigma_2>C$ et $\\sigma_2/\\sigma_1>C$:**\n",
    "\n",
    "    initialiser EM aléatoirement\n",
    "    appliquer l'algorithme EM\n",
    "    arrêter si sigma_2/sigma_1<C ou sigma_1/sigma_2<C\n",
    "    recommencer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "xmin=min(X.ravel())\n",
    "xmax=max(X.ravel())\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(xmin,xmax)\n",
    "plt.scatter(X[0,:],X[1,:],c=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
